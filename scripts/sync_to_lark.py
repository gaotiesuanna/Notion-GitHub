"""
ä»notionè¡¨æ ¼è·å–æ•°æ®, è§£æå¹¶ä¿å­˜ä¸ºæœ¬åœ°csvï¼ŒåŒæ—¶åŒæ­¥åˆ°é£ä¹¦åœ¨çº¿ç”µå­è¡¨æ ¼
"""
import os
from dotenv import load_dotenv
import requests
import csv
from typing import List, Dict, Any

load_dotenv()

def get_env(key: str):
    value = os.getenv(key)
    if not value:
        raise ValueError(f"{key}ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
    return value

# è·å–ç¯å¢ƒå˜é‡
notion_token = get_env("NOTION_TOKEN")
notion_database_id = os.getenv("NOTION_PROJECTS_DATABASE_ID") or get_env("NOTION_DATABASE_ID")
lark_app_id = get_env("LARK_APP_ID")
lark_app_secret = get_env("LARK_APP_SECRET")
lark_sheet_token = get_env("LARK_SHEET_TOKEN")  # ç”µå­è¡¨æ ¼token: MUQPsNc71hX0NJty5iOcf6d6nqd

def get_notion_data(token: str, database_id: str) -> list:
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    url = f"https://api.notion.com/v1/databases/{database_id}/query"
    response = requests.post(url, headers=headers, json={})

    if response.status_code == 200:
        results = response.json().get("results", [])        
        props = [page.get("properties") for page in results]
        return props
    else:
        print(f"Error: {response.status_code}")
        print(f"Response: {response.text}")
        return []

def trans(props) -> list[dict]:
    rows = []
    for prop in props:
        row = {}
        
        # title
        title = prop.get('é¡¹ç›®åç§°', {})
        title_list = title.get('title', []) if isinstance(title, dict) else []
        row['é¡¹ç›®åç§°'] = title_list[0]['plain_text'] if title_list else ''
        
        # GitHubé“¾æ¥
        row['GitHub é“¾æ¥'] = prop.get('GitHub é“¾æ¥', {}).get('url', '')

        # æè¿°
        rich_text = prop.get('æè¿°', {}).get('rich_text', [])
        row['æè¿°'] = ''.join(i.get('plain_text', '') for i in rich_text)
        
        # Stars
        Stars = prop.get('Stars', {})
        Stars_list = Stars.get("rich_text", []) if isinstance(Stars, dict) else []
        row['Stars'] = Stars_list[0]['plain_text'] if Stars_list else ''
        
        # Stars_init
        row['Stars_list'] = prop.get('Stars_init', {}).get('number', '')
        
        # Forks
        row['Forks'] = prop.get('Forks', {}).get('number', '')
        
        # Watchers
        row['Wathers'] = prop.get('Wathers', {}).get('number', '')
        
        # Open Issues
        row['Open Issues'] = prop.get('Open Issues', {}).get('number', '')
        
        # ä¸»è¦è¯­è¨€
        lang_dict = prop.get('ä¸»è¦è¯­è¨€', {}).get('select', {})
        row['ä¸»è¦è¯­è¨€'] = lang_dict.get('name', '') if isinstance(lang_dict, dict) else ''
        
        # æŠ€æœ¯æ ‡ç­¾
        tags = prop.get('æŠ€æœ¯æ ‡ç­¾', {}).get('multi_select', [])
        row['æŠ€æœ¯æ ‡ç­¾'] = ', '.join(i.get('name', '') for i in tags)
        
        # æœ€åæ›´æ–°
        date_updated = prop.get('æœ€åæ›´æ–°', {}).get('date', {})
        row['æœ€åæ›´æ–°'] = date_updated.get('start', '')[:10] if date_updated else ''
        
        # æœ€åæ¨é€
        date_pushed = prop.get('æœ€åæ¨é€', {}).get('date', {})
        row['æœ€åæ¨é€'] = date_pushed.get('start', '')[:10] if date_pushed else ''
        
        # ä½œè€…
        rt_author = prop.get('ä½œè€…', {}).get('rich_text', [])
        row['ä½œè€…'] = ''.join(i.get('plain_text', '') for i in rt_author)
        
        # è®¸å¯è¯
        License = prop.get('è®¸å¯è¯', {}).get('select', {})
        row['è®¸å¯è¯'] = License.get('name', '') if isinstance(License, dict) else ''
        
        # çŠ¶æ€
        state = prop.get('çŠ¶æ€', {}).get('select', {})
        row['çŠ¶æ€'] = state.get('name', '') if isinstance(state, dict) else ''
        
        # åˆ†ç±»
        Class = prop.get('åˆ†ç±»', {}).get('select', {})
        row['åˆ†ç±»'] = Class.get('name', '') if isinstance(Class, dict) else ''
        
        rows.append(row)
    return rows

def save_to_csv(rows: list[dict], filepath = "notion_export.csv"):
    if not rows:
        print("æ²¡æœ‰æ•°æ®")
        return
    
    fieldnames = list(rows[0].keys())
    
    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)
    
    print(f"å·²ä¿å­˜ {len(rows)} æ¡æ•°æ®åˆ° {filepath}")

def get_lark_access_token() -> str:
    """è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal/"
    headers = {
        "Content-Type": "application/json; charset=utf-8"
    }
    data = {
        "app_id": lark_app_id,
        "app_secret": lark_app_secret
    }
    
    print("æ­£åœ¨è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ...")
    response = requests.post(url, headers=headers, json=data)
    
    if response.status_code == 200:
        result = response.json()
        if result.get("code") == 0:
            access_token = result.get("tenant_access_token")
            print("âœ“ æˆåŠŸè·å–è®¿é—®ä»¤ç‰Œ")
            return access_token
        else:
            raise Exception(f"è·å–access tokenå¤±è´¥: {result}")
    else:
        raise Exception(f"è¯·æ±‚å¤±è´¥: {response.status_code}, {response.text}")

def get_sheet_info(access_token: str, sheet_token: str):
    """è·å–ç”µå­è¡¨æ ¼åŸºæœ¬ä¿¡æ¯"""
    print("æ­£åœ¨è·å–ç”µå­è¡¨æ ¼ä¿¡æ¯...")
    
    url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/metainfo"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json; charset=utf-8"
    }
    
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        result = response.json()
        if result.get("code") == 0:
            meta_info = result.get("data", {})
            print(f"è¡¨æ ¼æ ‡é¢˜: {meta_info.get('title', 'æœªçŸ¥')}")
            sheets = meta_info.get('sheets', [])
            print(f"å·¥ä½œè¡¨æ•°é‡: {len(sheets)}")
            for sheet in sheets:
                sheet_id = sheet.get('sheetId', sheet.get('sheet_id', ''))
                print(f"  - {sheet.get('title')} (sheet_id: {sheet_id})")
            return sheets
        else:
            print(f"è·å–è¡¨æ ¼ä¿¡æ¯å¤±è´¥: {result}")
    else:
        print(f"è·å–è¡¨æ ¼ä¿¡æ¯è¯·æ±‚å¤±è´¥: {response.status_code}")
        print(f"å“åº”å†…å®¹: {response.text}")
    return []

def clear_lark_sheet(access_token: str, sheet_token: str, sheet_id: str = "0"):
    """æ¸…ç©ºé£ä¹¦ç”µå­è¡¨æ ¼ä¸­çš„ç°æœ‰æ•°æ®"""
    print("æ­£åœ¨æ¸…ç©ºé£ä¹¦ç”µå­è¡¨æ ¼æ•°æ®...")
    
    # å…ˆè·å–ç°æœ‰æ•°æ®èŒƒå›´
    url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values_batch_get"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json; charset=utf-8"
    }
    
    # è·å–è¾ƒå¤§çš„èŒƒå›´æ¥æ£€æµ‹æ•°æ®
    params = {
        "ranges": [f"{sheet_id}!A1:Z1000"]
    }
    
    response = requests.get(url, headers=headers, params=params)
    if response.status_code == 200:
        result = response.json()
        if result.get("code") == 0:
            value_ranges = result.get("data", {}).get("valueRanges", [])
            if value_ranges:
                values = value_ranges[0].get("values", [])
                if values:
                    print(f"å‘ç° {len(values)} è¡Œæ•°æ®")
                    # æ¸…ç©ºæ•°æ® - å†™å…¥ç©ºå€¼åˆ°æ•´ä¸ªèŒƒå›´
                    clear_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values"
                    clear_data = {
                        "valueRange": {
                            "range": f"{sheet_id}!A1:Z{len(values)}",
                            "values": [["" for _ in range(26)] for _ in range(len(values))]
                        }
                    }
                    
                    clear_response = requests.put(clear_url, headers=headers, json=clear_data)
                    if clear_response.status_code == 200:
                        clear_result = clear_response.json()
                        if clear_result.get("code") == 0:
                            print("âœ“ æˆåŠŸæ¸…ç©ºç”µå­è¡¨æ ¼æ•°æ®")
                        else:
                            print(f"æ¸…ç©ºæ•°æ®å¤±è´¥: {clear_result}")
                    else:
                        print(f"æ¸…ç©ºæ•°æ®è¯·æ±‚å¤±è´¥: {clear_response.status_code}")
                else:
                    print("ç”µå­è¡¨æ ¼å·²ç»æ˜¯ç©ºçš„")
        else:
            print(f"è·å–è¡¨æ ¼æ•°æ®å¤±è´¥: {result}")
    else:
        print(f"è·å–è¡¨æ ¼æ•°æ®è¯·æ±‚å¤±è´¥: {response.status_code}")

def sync_to_lark_sheet(rows: List[Dict[str, Any]], access_token: str, sheet_token: str, sheet_id: str = "0"):
    """å°†æ•°æ®åŒæ­¥åˆ°é£ä¹¦ç”µå­è¡¨æ ¼"""
    if not rows:
        print("æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥")
        return
    
    print(f"æ­£åœ¨åŒæ­¥ {len(rows)} æ¡è®°å½•åˆ°é£ä¹¦ç”µå­è¡¨æ ¼...")
    
    url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json; charset=utf-8"
    }
    
    # å‡†å¤‡è¡¨å¤´
    if not rows:
        return
        
    fieldnames = list(rows[0].keys())
    
    # æ„é€ æ•°æ®çŸ©é˜µ
    values = []
    # æ·»åŠ è¡¨å¤´
    values.append(fieldnames)
    
    # æ·»åŠ æ•°æ®è¡Œ
    for row in rows:
        data_row = []
        for field in fieldnames:
            value = row.get(field, "")
            # å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®
            if field in ['Stars_list', 'Forks', 'Wathers', 'Open Issues']:
                data_row.append(int(value) if value and str(value).isdigit() else "")
            else:
                data_row.append(str(value) if value else "")
        values.append(data_row)
    
    # è®¡ç®—åˆ—å­—æ¯
    end_column = chr(64 + min(len(fieldnames), 26))  # A-Z
    end_row = len(values)
    
    # å†™å…¥æ•°æ®
    data = {
        "valueRange": {
            "range": f"{sheet_id}!A1:{end_column}{end_row}",
            "values": values
        }
    }
    
    print(f"æ­£åœ¨å†™å…¥æ•°æ®åˆ°èŒƒå›´: {sheet_id}!A1:{end_column}{end_row}")
    response = requests.put(url, headers=headers, json=data)
    if response.status_code == 200:
        result = response.json()
        if result.get("code") == 0:
            print("âœ“ æˆåŠŸåŒæ­¥æ•°æ®åˆ°é£ä¹¦ç”µå­è¡¨æ ¼")
        else:
            print(f"åŒæ­¥å¤±è´¥: {result}")
            print(f"è¯·æ±‚æ•°æ®: {data}")
    else:
        print(f"åŒæ­¥è¯·æ±‚å¤±è´¥: {response.status_code}")
        print(f"å“åº”å†…å®¹: {response.text}")
        print(f"è¯·æ±‚æ•°æ®: {data}")

def debug_sheet_operations(access_token: str, sheet_token: str, sheet_id: str):
    """è°ƒè¯•ç”µå­è¡¨æ ¼æ“ä½œ"""
    print("\n=== ç”µå­è¡¨æ ¼è°ƒè¯•ä¿¡æ¯ ===")
    
    # 1. æ£€æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨å’Œå¯è®¿é—®
    meta_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/metainfo"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json; charset=utf-8"
    }
    
    print("1. æ£€æŸ¥è¡¨æ ¼å…ƒä¿¡æ¯...")
    meta_response = requests.get(meta_url, headers=headers)
    print(f"   çŠ¶æ€ç : {meta_response.status_code}")
    if meta_response.status_code == 200:
        meta_result = meta_response.json()
        print(f"   å“åº”: {meta_result}")
        if meta_result.get("code") == 0:
            title = meta_result.get("data", {}).get("title", "æœªçŸ¥")
            print(f"   âœ“ è¡¨æ ¼æ ‡é¢˜: {title}")
            
            # æ˜¾ç¤ºå®é™…çš„sheetä¿¡æ¯
            sheets = meta_result.get("data", {}).get("sheets", [])
            print("   å®é™…å·¥ä½œè¡¨ä¿¡æ¯:")
            for sheet in sheets:
                actual_sheet_id = sheet.get('sheetId', sheet.get('sheet_id', 'unknown'))
                print(f"     - {sheet.get('title')} (sheetId: {actual_sheet_id})")
        else:
            print(f"   âœ— è·å–å…ƒä¿¡æ¯å¤±è´¥: {meta_result}")
    else:
        print(f"   âœ— è¯·æ±‚å¤±è´¥: {meta_response.text}")
    
    # 2. æ£€æŸ¥å·¥ä½œè¡¨æ˜¯å¦å­˜åœ¨
    print("\n2. æ£€æŸ¥å·¥ä½œè¡¨...")
    sheets = get_sheet_info(access_token, sheet_token)
    if sheets:
        print(f"   âœ“ æ‰¾åˆ° {len(sheets)} ä¸ªå·¥ä½œè¡¨")
        for i, sheet in enumerate(sheets):
            actual_sheet_id = sheet.get('sheetId', sheet.get('sheet_id', ''))
            print(f"     {i+1}. {sheet.get('title')} (ID: {actual_sheet_id})")
    else:
        print("   âœ— æœªæ‰¾åˆ°å·¥ä½œè¡¨")
    
    # 3. æµ‹è¯•å†™å…¥æƒé™ - å†™å…¥æµ‹è¯•æ•°æ®
    print("\n3. æµ‹è¯•å†™å…¥æƒé™...")
    test_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values"
    test_data = {
        "valueRange": {
            "range": f"{sheet_id}!A1:B2",  # ä½¿ç”¨ä¼ å…¥çš„æ­£ç¡®sheet_id
            "values": [
                ["æµ‹è¯•å­—æ®µ1", "æµ‹è¯•å­—æ®µ2"],
                ["æµ‹è¯•å€¼1", "æµ‹è¯•å€¼2"]
            ]
        }
    }
    
    test_response = requests.put(test_url, headers=headers, json=test_data)
    print(f"   å†™å…¥æµ‹è¯•çŠ¶æ€ç : {test_response.status_code}")
    if test_response.status_code == 200:
        test_result = test_response.json()
        print(f"   å†™å…¥æµ‹è¯•å“åº”: {test_result}")
        if test_result.get("code") == 0:
            print("   âœ“ å†™å…¥æµ‹è¯•æˆåŠŸ")
        else:
            print(f"   âœ— å†™å…¥æµ‹è¯•å¤±è´¥: {test_result}")
    else:
        print(f"   âœ— å†™å…¥æµ‹è¯•è¯·æ±‚å¤±è´¥: {test_response.text}")
    
    # 4. éªŒè¯å†™å…¥ç»“æœ
    print("\n4. éªŒè¯å†™å…¥ç»“æœ...")
    read_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values_batch_get"
    read_params = {"ranges": [f"{sheet_id}!A1:B2"]}  # ä½¿ç”¨ä¼ å…¥çš„æ­£ç¡®sheet_id
    read_response = requests.get(read_url, headers=headers, params=read_params)
    print(f"   è¯»å–æµ‹è¯•çŠ¶æ€ç : {read_response.status_code}")
    if read_response.status_code == 200:
        read_result = read_response.json()
        print(f"   è¯»å–æµ‹è¯•å“åº”: {read_result}")
        if read_result.get("code") == 0:
            values = read_result.get("data", {}).get("valueRanges", [{}])[0].get("values", [])
            print(f"   è¯»å–åˆ°çš„æ•°æ®: {values}")
        else:
            print(f"   âœ— è¯»å–æµ‹è¯•å¤±è´¥: {read_result}")
    else:
        print(f"   âœ— è¯»å–æµ‹è¯•è¯·æ±‚å¤±è´¥: {read_response.text}")

def sync_to_lark_sheet_debug(rows: List[Dict[str, Any]], access_token: str, sheet_token: str, sheet_id: str = "0"):
    """å¸¦è°ƒè¯•ä¿¡æ¯çš„æ•°æ®åŒæ­¥å‡½æ•°"""
    if not rows:
        print("æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥")
        return
    
    print(f"æ­£åœ¨åŒæ­¥ {len(rows)} æ¡è®°å½•åˆ°é£ä¹¦ç”µå­è¡¨æ ¼...")
    
    url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json; charset=utf-8"
    }
    
    # å‡†å¤‡è¡¨å¤´
    if not rows:
        return
        
    fieldnames = list(rows[0].keys())
    print(f"å­—æ®µåˆ—è¡¨: {fieldnames}")
    
    # æ„é€ æ•°æ®çŸ©é˜µ
    values = []
    # æ·»åŠ è¡¨å¤´
    values.append(fieldnames)
    
    # æ·»åŠ æ•°æ®è¡Œ
    for i, row in enumerate(rows[:3]):  # åªæ˜¾ç¤ºå‰3è¡Œä½œä¸ºç¤ºä¾‹
        data_row = []
        for field in fieldnames:
            value = row.get(field, "")
            # å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®
            if field in ['Stars_list', 'Forks', 'Wathers', 'Open Issues']:
                processed_value = int(value) if value and str(value).isdigit() else ""
            else:
                processed_value = str(value) if value else ""
            data_row.append(processed_value)
        values.append(data_row)
        print(f"ç¬¬{i+1}è¡Œæ•°æ®: {dict(zip(fieldnames, data_row))}")
    
    # æ·»åŠ å‰©ä½™è¡Œï¼ˆä¸æ˜¾ç¤ºè¯¦ç»†å†…å®¹ï¼‰
    for row in rows[3:]:
        data_row = []
        for field in fieldnames:
            value = row.get(field, "")
            if field in ['Stars_list', 'Forks', 'Wathers', 'Open Issues']:
                processed_value = int(value) if value and str(value).isdigit() else ""
            else:
                processed_value = str(value) if value else ""
            data_row.append(processed_value)
        values.append(data_row)
    
    # è®¡ç®—åˆ—å­—æ¯
    end_column = chr(64 + min(len(fieldnames), 26))  # A-Z
    end_row = len(values)
    
    print(f"\nå‡†å¤‡å†™å…¥çš„æ•°æ®èŒƒå›´: {sheet_id}!A1:{end_column}{end_row}")
    print(f"æ•°æ®çŸ©é˜µå¤§å°: {len(values)} è¡Œ Ã— {len(fieldnames)} åˆ—")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®é¢„è§ˆ
    print("\næ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
    for i, row in enumerate(values[:5]):
        print(f"  ç¬¬{i+1}è¡Œ: {row}")
    
    # å†™å…¥æ•°æ®
    data = {
        "valueRange": {
            "range": f"{sheet_id}!A1:{end_column}{end_row}",
            "values": values
        }
    }
    
    print(f"\næ­£åœ¨æ‰§è¡Œå†™å…¥æ“ä½œ...")
    response = requests.put(url, headers=headers, json=data)
    print(f"å†™å…¥è¯·æ±‚çŠ¶æ€ç : {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        print(f"å†™å…¥å“åº”: {result}")
        if result.get("code") == 0:
            print("âœ“ æˆåŠŸåŒæ­¥æ•°æ®åˆ°é£ä¹¦ç”µå­è¡¨æ ¼")
            
            # éªŒè¯å†™å…¥ç»“æœ
            print("\næ­£åœ¨éªŒè¯å†™å…¥ç»“æœ...")
            verify_url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{sheet_token}/values_batch_get"
            verify_params = {"ranges": [f"{sheet_id}!A1:{end_column}{min(end_row, 10)}"]}  # åªéªŒè¯å‰10è¡Œ
            verify_response = requests.get(verify_url, headers=headers, params=verify_params)
            if verify_response.status_code == 200:
                verify_result = verify_response.json()
                if verify_result.get("code") == 0:
                    verified_values = verify_result.get("data", {}).get("valueRanges", [{}])[0].get("values", [])
                    print(f"éªŒè¯è¯»å–åˆ° {len(verified_values)} è¡Œæ•°æ®:")
                    for i, row in enumerate(verified_values[:3]):
                        print(f"  éªŒè¯ç¬¬{i+1}è¡Œ: {row}")
                else:
                    print(f"éªŒè¯è¯»å–å¤±è´¥: {verify_result}")
            else:
                print(f"éªŒè¯è¯»å–è¯·æ±‚å¤±è´¥: {verify_response.status_code}")
                
        else:
            print(f"åŒæ­¥å¤±è´¥: {result}")
            print(f"è¯·æ±‚æ•°æ®: {data}")
    else:
        print(f"åŒæ­¥è¯·æ±‚å¤±è´¥: {response.status_code}")
        print(f"å“åº”å†…å®¹: {response.text}")
        print(f"è¯·æ±‚æ•°æ®: {data}")

def main():
    try:
        # è·å–Notionæ•°æ®
        print("æ­£åœ¨è·å–Notionæ•°æ®...")
        props = get_notion_data(notion_token, notion_database_id)
        rows = trans(props)
        
        if not rows:
            print("æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return
        
        print(f"âœ“ æˆåŠŸè·å– {len(rows)} æ¡Notionæ•°æ®")
        
        # ä¿å­˜åˆ°CSV
        # save_to_csv(rows)
        
        # è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ
        access_token = get_lark_access_token()
        
        # è°ƒè¯•æ¨¡å¼ - å…ˆè¿›è¡Œè°ƒè¯•
        print("\n" + "="*50)
        print("å¼€å§‹è°ƒè¯•æ¨¡å¼...")
        debug_sheet_operations(access_token, lark_sheet_token, "951b55")  # ä½¿ç”¨æ­£ç¡®çš„sheet_id
        print("="*50 + "\n")
        
        # è·å–è¡¨æ ¼ä¿¡æ¯
        sheets = get_sheet_info(access_token, lark_sheet_token)
        target_sheet_id = "951b55"  # ä½¿ç”¨å®é™…çš„sheet_idè€Œä¸æ˜¯é»˜è®¤çš„"0"
        if sheets:
            # ä¼˜å…ˆä½¿ç”¨è¿”å›çš„å®é™…sheet_id
            actual_sheet_id = sheets[0].get('sheetId', sheets[0].get('sheet_id', '951b55'))
            if actual_sheet_id:
                target_sheet_id = actual_sheet_id
            print(f"ä½¿ç”¨å·¥ä½œè¡¨: {sheets[0].get('title')} (ID: {target_sheet_id})")
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        clear_lark_sheet(access_token, lark_sheet_token, target_sheet_id)
        
        # åŒæ­¥æ–°æ•°æ®ï¼ˆä½¿ç”¨è°ƒè¯•ç‰ˆæœ¬ï¼‰
        sync_to_lark_sheet_debug(rows, access_token, lark_sheet_token, target_sheet_id)
        
        print(f"\nğŸ‰ æ•°æ®åŒæ­¥å®Œæˆï¼å…±å¤„ç† {len(rows)} æ¡è®°å½•")
        print(f"é£ä¹¦ç”µå­è¡¨æ ¼é“¾æ¥: https://my.feishu.cn/sheets/{lark_sheet_token}")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
